import streamlit as st
import pandas as pd
import plotly.express as px
from groq import Groq
import io
import xlsxwriter
from datetime import datetime
import calendar

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
st.set_page_config(page_title="SalesPro Analytics", layout="wide")

# --- 1. –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø ---
def check_auth():
    if "authenticated" not in st.session_state:
        st.session_state["authenticated"] = False

    if st.session_state["authenticated"]:
        return True

    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("üîê SalesPro Analytics Enterprise")
        st.write("–í–≤–µ–¥–∏—Ç–µ –ª–∏—Ü–µ–Ω–∑–∏–æ–Ω–Ω—ã–π –∫–ª—é—á –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–∏—Å—Ç–µ–º–µ.")
        password = st.text_input("License Key", type="password")
        if st.button("–í–æ–π—Ç–∏ –≤ —Å–∏—Å—Ç–µ–º—É", type="primary", use_container_width=True):
            if password == "START-500":
                st.session_state["authenticated"] = True
                st.rerun()
            else:
                st.error("‚õî –ù–µ–≤–µ—Ä–Ω—ã–π –∫–ª—é—á –∞–∫—Ç–∏–≤–∞—Ü–∏–∏")
    return False

if not check_auth():
    st.stop()

# --- 2. –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ---

def calculate_forecast_metrics(df_branch):
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–≥–Ω–æ–∑–∞: –¥–Ω–µ–π —Ä–∞–±–æ—Ç—ã, —Å—Ä–µ–¥–Ω–µ–µ –≤ –¥–µ–Ω—å, –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –º–µ—Å—è—Ü.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏.
    """
    metrics = {
        "days_worked": 0,
        "avg_daily": 0,
        "forecast": 0,
        "days_in_month": 30
    }
    
    if df_branch.empty:
        return metrics
        
    try:
        dates = pd.to_datetime(df_branch['–î–∞—Ç–∞'], errors='coerce').dropna().dt.date.unique()
        metrics["days_worked"] = len(dates)
        
        if metrics["days_worked"] == 0:
            return metrics
            
        current_fact = df_branch['–ü—Ä–æ–¥–∞–∂–∏'].sum()
        metrics["avg_daily"] = current_fact / metrics["days_worked"]
        
        first_date_val = df_branch['–î–∞—Ç–∞'].iloc[0]
        if not pd.isna(first_date_val):
            first_date = pd.to_datetime(first_date_val)
            metrics["days_in_month"] = calendar.monthrange(first_date.year, first_date.month)[1]
        
        metrics["forecast"] = metrics["avg_daily"] * metrics["days_in_month"]
        return metrics
    except Exception:
        metrics["forecast"] = df_branch['–ü—Ä–æ–¥–∞–∂–∏'].sum()
        return metrics

def generate_template():
    """–°–æ–∑–¥–∞–µ—Ç Excel —Ñ–∞–π–ª-–æ–±—Ä–∞–∑–µ—Ü —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π"""
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
        workbook = writer.book
        worksheet = workbook.add_worksheet('–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è')
        
        bold_head = workbook.add_format({'bold': True, 'font_size': 14, 'color': '#2c3e50'})
        text_norm = workbook.add_format({'font_size': 12, 'text_wrap': True, 'valign': 'top'})
        text_red = workbook.add_format({'bold': True, 'color': 'red', 'font_size': 12})
        
        worksheet.write('A1', '–ö–∞–∫ –∑–∞–ø–æ–ª–Ω–∏—Ç—å —à–∞–±–ª–æ–Ω –ø–æ–¥ —Å–≤–æ–π –±–∏–∑–Ω–µ—Å:', bold_head)
        
        rules = [
            "",
            "1. –í –≤–µ—Ä—Ö–Ω–µ–π —Å—Ç—Ä–æ–∫–µ (–≤ –ª–∏—Å—Ç–∞—Ö '–§–∞–∫—Ç' –∏ '–ü–ª–∞–Ω') –ø–∏—à–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –≤–∞—à–∏—Ö —Ç–æ—á–µ–∫.",
            "   (–ù–∞–ø—Ä–∏–º–µ—Ä: –ú–∞–≥–∞–∑–∏–Ω—ã, –°–∫–ª–∞–¥—ã, –û—Ñ–∏—Å—ã, –§–∏–ª–∏–∞–ª—ã).",
            "",
            "2. –ü–æ–¥ –∫–∞–∂–¥—ã–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ç–æ—á–∫–∏ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–π.",
            "   –í—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –∏—Ö –∫–∞–∫ —Ö–æ—Ç–∏—Ç–µ.",
            "   (–ù–∞–ø—Ä–∏–º–µ—Ä: –¢–æ–≤–∞—Ä—ã, –£—Å–ª—É–≥–∏, –î–æ—Å—Ç–∞–≤–∫–∞ –∏–ª–∏ –û–ø—Ç, –†–æ–∑–Ω–∏—Ü–∞, –ò–Ω—Ç–µ—Ä–Ω–µ—Ç).",
            "",
            "3. –í—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–ª—è—Ç—å –Ω–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏–ª–∏ —É–¥–∞–ª—è—Ç—å –ª–∏—à–Ω–∏–µ.",
            ""
        ]
        
        row = 1
        for line in rules:
            worksheet.write(row, 0, line, text_norm)
            row += 1
        
        worksheet.write(row, 0, '–í–∞–∂–Ω–æ: –ù–µ —É–¥–∞–ª—è–π—Ç–µ –∫–æ–ª–æ–Ω–∫—É "–ò–¢–û–ì–û", –æ–Ω–∞ –Ω—É–∂–Ω–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–ª–∞–Ω–æ–≤.', text_red)
        worksheet.set_column('A:A', 70)

        # –õ–ò–°–¢ 2: –§–ê–ö–¢
        df_fact = pd.DataFrame([
            ["–î–∞—Ç–∞", "–ú–∞–≥–∞–∑–∏–Ω –¶–µ–Ω—Ç—Ä", "", "", "–ú–∞–≥–∞–∑–∏–Ω –°–∫–ª–∞–¥", "", ""],
            ["", "–ö–∏—Ä–ø–∏—á", "–¶–µ–º–µ–Ω—Ç", "–ö—Ä–∞—Å–∫–∞", "–ö–∏—Ä–ø–∏—á", "–¶–µ–º–µ–Ω—Ç", "–ö—Ä–∞—Å–∫–∞"],
            ["2025-05-01", 5000, 3000, 1000, 4000, 2000, 500],
            ["2025-05-02", 5200, 3100, 1100, 4100, 2100, 550]
        ])
        df_fact.to_excel(writer, sheet_name='–§–∞–∫—Ç', index=False, header=False)
        
        # –õ–ò–°–¢ 3: –ü–õ–ê–ù
        df_plan = pd.DataFrame([
            ["–ú–µ—Å—è—Ü", "–ì–æ–¥", "–ú–∞–≥–∞–∑–∏–Ω –¶–µ–Ω—Ç—Ä", "", "", "", "–ú–∞–≥–∞–∑–∏–Ω –°–∫–ª–∞–¥", "", "", ""],
            ["", "", "–ö–∏—Ä–ø–∏—á", "–¶–µ–º–µ–Ω—Ç", "–ö—Ä–∞—Å–∫–∞", "–ò–¢–û–ì–û", "–ö–∏—Ä–ø–∏—á", "–¶–µ–º–µ–Ω—Ç", "–ö—Ä–∞—Å–∫–∞", "–ò–¢–û–ì–û"],
            ["–ú–∞–π", 2025, 150000, 100000, 50000, 300000, 100000, 80000, 20000, 200000]
        ])
        df_plan.to_excel(writer, sheet_name='–ü–ª–∞–Ω', index=False, header=False)
        
    buffer.seek(0)
    return buffer

# --- 3. –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ---
@st.cache_data
def load_data_and_plan(file):
    try:
        xl = pd.ExcelFile(file)
        sheet_names = xl.sheet_names
        
        # –ò—â–µ–º –ª–∏—Å—Ç –§–ê–ö–¢
        fact_sheet = None
        for s in sheet_names:
            if '—Ñ–∞–∫—Ç' in s.lower() or 'fact' in s.lower():
                fact_sheet = s
                break
        if not fact_sheet:
            for s in sheet_names:
                name_lower = s.lower()
                if "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è" not in name_lower and "instruction" not in name_lower and "–ø–ª–∞–Ω" not in name_lower and "plan" not in name_lower:
                    fact_sheet = s
                    break
        if not fact_sheet and len(sheet_names) > 1:
            fact_sheet = sheet_names[1]
            
        if not fact_sheet:
            return None, {}

        # –ß–∏—Ç–∞–µ–º –§–ê–ö–¢
        df_fact_raw = pd.read_excel(file, sheet_name=fact_sheet, header=None)
        
        row0 = df_fact_raw.iloc[0].tolist()
        row1 = df_fact_raw.iloc[1].tolist()
        
        branches = []
        curr = "Unknown"
        for item in row0:
            if pd.notna(item) and str(item).strip() != "":
                if "–¥–∞—Ç–∞" not in str(item).lower():
                    curr = str(item).strip()
            branches.append(curr)
            
        fact_data = []
        for idx, row in df_fact_raw.iloc[2:].iterrows():
            date_val = row[0]
            if pd.isna(date_val): continue
            
            start_col = 1
            for col_idx in range(start_col, len(row)):
                if col_idx >= len(branches): break
                branch = branches[col_idx]
                if col_idx >= len(row1): break
                channel = row1[col_idx]
                val = row[col_idx]
                
                invalid_words = ['–∏—Ç–æ–≥–æ', 'total', '—Å—É–º–º–∞', 'nan', 'none', '–¥–∞—Ç–∞', '–¥–µ–Ω—å']
                channel_str = str(channel).strip()
                
                if (branch != "Unknown" 
                    and channel_str 
                    and channel_str.lower() not in invalid_words 
                    and pd.notna(channel)):
                    
                    fact_data.append({
                        '–î–∞—Ç–∞': date_val,
                        '–§–∏–ª–∏–∞–ª': branch,
                        '–ö–∞–Ω–∞–ª': channel_str.capitalize(),
                        '–ü—Ä–æ–¥–∞–∂–∏': val if pd.notna(val) else 0
                    })
        df_sales = pd.DataFrame(fact_data)

        # –ß–∏—Ç–∞–µ–º –ü–õ–ê–ù
        plans_map = {}
        plan_sheet_name = next((s for s in sheet_names if '–ø–ª–∞–Ω' in s.lower() or 'plan' in s.lower()), None)
        
        if plan_sheet_name:
            df_plan_raw = pd.read_excel(file, sheet_name=plan_sheet_name, header=None)
            p_row0 = df_plan_raw.iloc[0].tolist()
            p_row1 = df_plan_raw.iloc[1].tolist()
            p_values = df_plan_raw.iloc[2].tolist()
            
            p_branches = []
            p_curr = "Unknown"
            for i in range(len(p_row0)):
                item = p_row0[i]
                if pd.notna(item) and str(item).strip() != "":
                     if "–º–µ—Å—è—Ü" not in str(item).lower() and "–≥–æ–¥" not in str(item).lower():
                        p_curr = str(item).strip()
                p_branches.append(p_curr)

            for i, val in enumerate(p_values):
                if i >= len(p_branches) or i >= len(p_row1): break
                branch = p_branches[i]
                channel = p_row1[i]
                
                if (pd.notna(val) 
                    and branch != "Unknown"
                    and str(channel).lower().strip() in ['–∏—Ç–æ–≥–æ', 'total', '—Å—É–º–º–∞']):
                     plans_map[branch] = val

        return df_sales, plans_map

    except Exception as e:
        return None, {}

def get_ai_advice(branch, plan, fact_df):
    try:
        api_key = st.secrets["GROQ_API_KEY"]
    except:
        return "‚ö†Ô∏è –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω GROQ_API_KEY –≤ Streamlit Secrets."

    total_fact = fact_df['–ü—Ä–æ–¥–∞–∂–∏'].sum()
    percent = (total_fact / plan * 100) if plan > 0 else 0
    
    metrics = calculate_forecast_metrics(fact_df)
    forecast_val = metrics["forecast"]
    avg_daily = metrics["avg_daily"]
    days_passed = metrics["days_worked"]
    
    fact_channels = fact_df.groupby('–ö–∞–Ω–∞–ª')['–ü—Ä–æ–¥–∞–∂–∏'].sum().to_dict()
    fact_channels_str = str(fact_channels)
    
    details_list = []
    daily_groups = fact_df.groupby(['–î–∞—Ç–∞', '–ö–∞–Ω–∞–ª'])['–ü—Ä–æ–¥–∞–∂–∏'].sum().unstack(fill_value=0)
    for date_idx, row in daily_groups.iterrows():
        date_str = pd.to_datetime(date_idx).strftime('%Y-%m-%d')
        channels_str = ", ".join([f"{col}={val:.0f}" for col, val in row.items()])
        total_day = row.sum()
        details_list.append(f"{date_str}: {channels_str}, –ò—Ç–æ–≥–æ={total_day:.0f}")
    
    details_text = "\n".join(details_list[-20:])

    prompt = f"""
    –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∞–Ω–Ω—ã–µ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º –¥–ª—è –æ–±—ä–µ–∫—Ç–∞: "{branch}".
    
    –ü–õ–ê–ù–û–í–´–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò (–º–µ—Å):
    - –û–±—â–∏–π –ø–ª–∞–Ω: {plan:,.0f}
    
    –§–ê–ö–¢–ò–ß–ï–°–ö–ò–ï –ü–û–ö–ê–ó–ê–¢–ï–õ–ò (–∑–∞ {days_passed} –¥–Ω–µ–π –ø—Ä–æ–¥–∞–∂):
    - –û–±—â–∏–π —Ñ–∞–∫—Ç: {total_fact:,.0f} ({percent:.1f}% –æ—Ç –ø–ª–∞–Ω–∞).
    - –§–∞–∫—Ç –ø–æ –∫–∞–Ω–∞–ª–∞–º/–∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {fact_channels_str}
    
    –î–ò–ù–ê–ú–ò–ö–ê:
    - –°—Ä–µ–¥–Ω–µ—Å—É—Ç–æ—á–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏: {avg_daily:,.0f}
    - –ü—Ä–æ–≥–Ω–æ–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –Ω–∞ –∫–æ–Ω–µ—Ü –º–µ—Å—è—Ü–∞: {forecast_val:,.0f}
    
    –ü–û–î–†–û–ë–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–î–ê–ñ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–Ω–∏):
    {details_text}
    
    –ó–ê–î–ê–ß–ê:
    –ü–æ–¥–≥–æ—Ç–æ–≤—å –∫—Ä–∞—Ç–∫–∏–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –≤ —Å—Ç—Ä–æ–≥–æ–º –¥–µ–ª–æ–≤–æ–º —Å—Ç–∏–ª–µ (Markdown).
    1. –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–µ–∫—É—â–µ–≥–æ —Ç–µ–º–ø–∞ (—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–≥–Ω–æ–∑–∞ –∏ –ø–ª–∞–Ω–∞).
    2. –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞–Ω–∞–ª–∞–º: –∫–∞–∫–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –Ω–∞–∏–±–æ–ª—å—à–µ–µ –æ—Ç—Å—Ç–∞–≤–∞–Ω–∏–µ –∏–ª–∏ –ø—Ä–æ–≤–∞–ª.
    3. –ê–Ω–∞–ª–∏–∑ –¥–∏–Ω–∞–º–∏–∫–∏: –µ—Å—Ç—å –ª–∏ –∑–∞–º–µ—Ç–Ω—ã–µ —Å–ø–∞–¥—ã –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–Ω–∏.
    4. –¢–æ—á–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑: –±—É–¥–µ—Ç –ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω –ø–ª–∞–Ω –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ç–µ–º–ø–∞.
    5. –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—è –æ–±—ä–µ–∫—Ç–∞.
    """
    
    try:
        client = Groq(api_key=api_key)
        chat = client.chat.completions.create(
            messages=[{"role": "user", "content": prompt}],
            model="llama-3.3-70b-versatile"
        )
        return chat.choices[0].message.content
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ AI —Å–µ—Ä–≤–∏—Å–∞: {e}"

# --- 4. –ì–õ–ê–í–ù–´–ô –≠–ö–†–ê–ù ---
st.title("üìä SalesPro Analytics Dashboard")

with st.sidebar:
    st.header("–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ")
    template_file = generate_template()
    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–µ–π",
        data=template_file,
        file_name="sales_template_universal.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
    st.divider()
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç—å –æ—Ç—á–µ—Ç (.xlsx)", type="xlsx")

if uploaded_file:
    df, plans_map = load_data_and_plan(uploaded_file)
    
    if df is not None and not df.empty:
        all_branches = sorted(df['–§–∏–ª–∏–∞–ª'].unique())
        selected_branch = st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –æ–±—ä–µ–∫—Ç/—Ñ–∏–ª–∏–∞–ª", all_branches)
        
        df_branch = df[df['–§–∏–ª–∏–∞–ª'] == selected_branch]
        auto_plan = plans_map.get(selected_branch, 0)
        
        if auto_plan == 0:
            st.warning(f"–ü–ª–∞–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Ñ–∞–π–ª–µ. –í–≤–µ–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é.")
            target_plan = st.sidebar.number_input("–ü–ª–∞–Ω –ø—Ä–æ–¥–∞–∂", value=200000)
        else:
            st.sidebar.success(f"–ü–ª–∞–Ω –ø–æ–¥–≥—Ä—É–∂–µ–Ω: {auto_plan:,.0f}")
            target_plan = auto_plan
            
        fact = df_branch['–ü—Ä–æ–¥–∞–∂–∏'].sum()
        delta = fact - target_plan
        percent = (fact / target_plan) * 100 if target_plan > 0 else 0
        
        fc_metrics = calculate_forecast_metrics(df_branch)
        forecast_val = fc_metrics["forecast"]
        forecast_delta = forecast_val - target_plan
        
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("üéØ –ü–ª–∞–Ω", f"{target_plan:,.0f}")
        col2.metric("üí∞ –§–∞–∫—Ç", f"{fact:,.0f}", f"{percent:.1f}%")
        col3.metric("üìâ –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ", f"{delta:,.0f}", delta_color="normal")
        
        col4.metric(
            "üîÆ –ü—Ä–æ–≥–Ω–æ–∑ (–∫–æ–Ω–µ—Ü –º–µ—Å.)", 
            f"{forecast_val:,.0f}", 
            f"{forecast_delta:,.0f}", 
            delta_color="normal"
        )

        st.divider()
        c1, c2 = st.columns([2, 1])
        with c1:
            st.subheader("üìÜ –î–∏–Ω–∞–º–∏–∫–∞")
            df_trend = df_branch.groupby('–î–∞—Ç–∞')['–ü—Ä–æ–¥–∞–∂–∏'].sum().reset_index()
            fig_trend = px.area(df_trend, x='–î–∞—Ç–∞', y='–ü—Ä–æ–¥–∞–∂–∏', color_discrete_sequence=['#00CC96'])
            st.plotly_chart(fig_trend, use_container_width=True)
        with c2:
            st.subheader("üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞")
            df_pie = df_branch.groupby('–ö–∞–Ω–∞–ª')['–ü—Ä–æ–¥–∞–∂–∏'].sum().reset_index()
            fig_pie = px.pie(df_pie, values='–ü—Ä–æ–¥–∞–∂–∏', names='–ö–∞–Ω–∞–ª', hole=0.5)
            st.plotly_chart(fig_pie, use_container_width=True)

        st.divider()
        if st.button("üß† AI –ë–∏–∑–Ω–µ—Å-–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç", type="primary", use_container_width=True):
            with st.spinner("–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö..."):
                report = get_ai_advice(selected_branch, target_plan, df_branch)
                st.markdown(report)
    else:
        st.error("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞. –°–∫–∞—á–∞–π—Ç–µ —à–∞–±–ª–æ–Ω —Å–ª–µ–≤–∞.")
else:
    st.info("üëà –ù–∞—á–Ω–∏—Ç–µ —Ä–∞–±–æ—Ç—É —Å –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞.")
